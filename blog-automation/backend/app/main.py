from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import structlog

from app.core.config import settings
# from app.api import auth, users, contents, blog_accounts, publications, analytics
from app.core.database import supabase_client


# Configure structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("Starting up Blog Automation System")
    
    # Test Supabase connection
    try:
        result = supabase_client.table('blog_platforms').select("*").limit(1).execute()
        logger.info(f"Supabase connection successful, found {len(result.data)} blog platforms")
    except Exception as e:
        logger.error(f"Supabase connection failed: {e}")
    
    yield
    
    # Shutdown
    logger.info("Shutting down Blog Automation System")


# Create FastAPI app
app = FastAPI(
    title=settings.app_name,
    version="1.0.0",
    lifespan=lifespan,
    docs_url="/docs" if settings.debug else None,
    redoc_url="/redoc" if settings.debug else None,
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers (Temporarily disabled - need to update to Supabase)
# TODO: Update these routers to use Supabase instead of SQLAlchemy
# app.include_router(auth.router, prefix=f"{settings.api_prefix}/auth", tags=["auth"])
# app.include_router(users.router, prefix=f"{settings.api_prefix}/users", tags=["users"])
# app.include_router(contents.router, prefix=f"{settings.api_prefix}/contents", tags=["contents"])
# app.include_router(blog_accounts.router, prefix=f"{settings.api_prefix}/blog-accounts", tags=["blog-accounts"])
# app.include_router(publications.router, prefix=f"{settings.api_prefix}/publications", tags=["publications"])
# app.include_router(analytics.router, prefix=f"{settings.api_prefix}/analytics", tags=["analytics"])


@app.get("/")
async def root():
    return {"message": "Welcome to Blog Automation System API"}


@app.get("/health")
async def health_check():
    try:
        # Check Supabase connection
        result = supabase_client.table('blog_platforms').select("count").execute()
        return {
            "status": "healthy",
            "supabase": "connected",
            "database": "ready"
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "supabase": "error",
            "error": str(e)
        }


# Dashboard endpoints (temporary mock data)
@app.get("/dashboard/stats")
async def get_dashboard_stats():
    """ëŒ€ì‹œë³´ë“œ í†µê³„ ì •ë³´ - Supabase ì‹¤ì œ ë°ì´í„°"""
    try:
        # í”Œë«í¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        platforms_result = supabase_client.table('blog_platforms').select("*").execute()
        platforms = platforms_result.data or []
        
        # ì‹¤ì œ í¬ìŠ¤íŠ¸ ìˆ˜ ê³„ì‚° (blog_posts í…Œì´ë¸” ì‚¬ìš©)
        posts_result = supabase_client.table('blog_posts').select("id").execute()
        total_posts = len(posts_result.data) if posts_result.data else 0
        
        # ìµœê·¼ í¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        posts_response = await get_posts()
        recent_posts = posts_response["posts"][:5]
        
        # ê° í”Œë«í¼ì˜ ì‹¤ì œ í†µê³„ ê³„ì‚° (blog_posts í…Œì´ë¸”ì—ì„œ)
        for platform in platforms:
            platform_id = platform.get('id')
            
            # í•´ë‹¹ í”Œë«í¼ì˜ í¬ìŠ¤íŠ¸ë“¤
            platform_posts_result = supabase_client.table('blog_posts').select(
                "views, likes, comments"
            ).eq('platform_id', platform_id).execute()
            
            if platform_posts_result.data:
                total_views = sum(post.get('views', 0) for post in platform_posts_result.data)
                total_likes = sum(post.get('likes', 0) for post in platform_posts_result.data)
                total_comments = sum(post.get('comments', 0) for post in platform_posts_result.data)
                post_count = len(platform_posts_result.data)
            else:
                total_views = total_likes = total_comments = post_count = 0
            
            # í”Œë«í¼ ë°ì´í„° ì—…ë°ì´íŠ¸ (ì‹¤ì œ ê³„ì‚°ëœ ê°’ìœ¼ë¡œ)
            platform['post_count'] = post_count
            platform['total_views'] = total_views
            platform['total_likes'] = total_likes
            platform['total_comments'] = total_comments
        
        return {
            "total_posts": total_posts,
            "platforms": platforms,
            "recent_posts": recent_posts
        }
    except Exception as e:
        logger.error(f"Dashboard stats error: {e}")
        return {
            "total_posts": 0,
            "platforms": [],
            "recent_posts": []
        }


@app.get("/dashboard/publishing-activity")
async def get_publishing_activity():
    """ë°œí–‰ í™œë™ ë°ì´í„° (GitHub ìŠ¤íƒ€ì¼ ìº˜ë¦°ë”ìš©) - Supabase ì‹¤ì œ ë°ì´í„°"""
    from datetime import datetime, timedelta
    from collections import defaultdict
    
    try:
        # Supabaseì—ì„œ ì‹¤ì œ ë°œí–‰ëœ í¬ìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (blog_posts í…Œì´ë¸” ì‚¬ìš©)
        posts_result = supabase_client.table('blog_posts').select("*").order('created_at', desc=True).execute()
        posts = posts_result.data or []
        
        # 365ì¼ ê¸°ê°„ ì„¤ì •
        end_date = datetime.now()
        start_date = end_date - timedelta(days=364)
        
        # ë‚ ì§œë³„ í¬ìŠ¤íŠ¸ ê·¸ë£¹í™”
        posts_by_date = defaultdict(list)
        
        for post in posts:
            created_at = post.get('created_at')
            if created_at:
                try:
                    post_date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                    post_date = post_date.date()
                    
                    # 365ì¼ ë²”ìœ„ ë‚´ì˜ ë°ì´í„°ë§Œ í¬í•¨
                    if start_date.date() <= post_date <= end_date.date():
                        posts_by_date[post_date.strftime("%Y-%m-%d")].append(post.get('title', 'ì œëª© ì—†ìŒ'))
                except:
                    continue
        
        # 365ì¼ í™œë™ ë°ì´í„° ìƒì„±
        activities = []
        total_posts = 0
        active_days = 0
        
        current_date = start_date
        while current_date <= end_date:
            date_str = current_date.strftime("%Y-%m-%d")
            posts = posts_by_date.get(date_str, [])
            count = len(posts)
            
            if count > 0:
                active_days += 1
                total_posts += count
            
            activities.append({
                "date": date_str,
                "count": count,
                "posts": posts
            })
            
            current_date += timedelta(days=1)
        
        return {
            "activities": activities,
            "total_posts": total_posts,
            "active_days": active_days,
            "date_range": {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        }
        
    except Exception as e:
        logger.error(f"Publishing activity data error: {e}")
        return {
            "activities": [],
            "total_posts": 0,
            "active_days": 0,
            "date_range": {
                "start": datetime.now().strftime("%Y-%m-%d"),
                "end": datetime.now().strftime("%Y-%m-%d")
            }
        }


@app.get("/dashboard/posts")
async def get_posts():
    """ë°œí–‰ëœ í¬ìŠ¤íŠ¸ ëª©ë¡ - Supabase ì‹¤ì œ ë°ì´í„°"""
    try:
        # Supabaseì—ì„œ ì‹¤ì œ í¬ìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (blog_postsì™€ blog_platforms ì¡°ì¸)
        posts_result = supabase_client.table('blog_posts').select(
            "*, blog_platforms!inner(id, name, platform_type, url)"
        ).order('created_at', desc=True).execute()
        
        posts = []
        
        for post_data in posts_result.data or []:
            platform_info = post_data.get('blog_platforms', {})
            
            post = {
                "id": post_data.get('id'),
                "title": post_data.get('title', 'ì œëª© ì—†ìŒ'),
                "platform": {
                    "name": platform_info.get('name', 'ì•Œ ìˆ˜ ì—†ëŠ” í”Œë«í¼'),
                    "platform_type": platform_info.get('platform_type', 'unknown'),
                    "url": platform_info.get('url', '')
                },
                "blog_platforms": platform_info,  # RecentPosts ì»´í¬ë„ŒíŠ¸ì—ì„œ ì‚¬ìš©
                "published_url": post_data.get('published_url', ''),
                "status": post_data.get('status', 'draft'),
                "views": post_data.get('views', 0),
                "likes": post_data.get('likes', 0),
                "comments": post_data.get('comments', 0),
                "created_at": post_data.get('created_at'),
                "published_at": post_data.get('published_at')
            }
            posts.append(post)
        
        return {"posts": posts}
        
    except Exception as e:
        logger.error(f"Posts data error: {e}")
        return {"posts": []}


@app.get("/dashboard/platforms")
async def get_platforms():
    """ì—°ê²°ëœ í”Œë«í¼ ëª©ë¡"""
    try:
        result = supabase_client.table('blog_platforms').select("*").execute()
        return {
            "platforms": result.data
        }
    except Exception as e:
        return {
            "platforms": [],
            "error": str(e)
        }


@app.post("/dashboard/platforms")
async def add_platform(platform: dict):
    """ìƒˆ í”Œë«í¼ ì¶”ê°€"""
    return {
        "success": False,
        "message": "API implementation pending"
    }


@app.post("/test/publish")
async def test_publish(request: dict):
    """Claude APIë¥¼ ì‚¬ìš©í•œ ì½˜í…ì¸  ìƒì„± ë° ë°œí–‰ í…ŒìŠ¤íŠ¸"""
    from datetime import datetime
    import random
    from app.services.claude_service import get_claude_generator
    
    try:
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        keywords = request.get('keywords', [])
        content_type = request.get('content_type', 'blog_post')
        target_length = request.get('target_length', 3000)
        tone = request.get('tone', 'ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸')
        
        if not keywords:
            return {
                "success": False,
                "message": "í‚¤ì›Œë“œë¥¼ ìµœì†Œ 1ê°œ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”"
            }
        
        # Claude APIë¥¼ ì‚¬ìš©í•œ ì½˜í…ì¸  ìƒì„±
        try:
            claude_generator = get_claude_generator()
            claude_content = claude_generator.generate_content(
                keywords=keywords,
                content_type=content_type,
                target_length=target_length,
                tone=tone
            )
            
            logger.info(f"Claude API ì½˜í…ì¸  ìƒì„± ì„±ê³µ", 
                       target_length=target_length,
                       actual_length=claude_content.get("word_count", 0))
            
        except Exception as claude_error:
            logger.error(f"Claude API ì‹¤íŒ¨: {claude_error}")
            
            # í…ŒìŠ¤íŠ¸ìš© ëŒ€ì²´ ì½˜í…ì¸  ìƒì„±
            main_keyword = keywords[0] if keywords else "ì£¼ì œ"
            
            # í†¤ì— ë§ëŠ” ìŠ¤íƒ€ì¼ ì„ íƒ
            tone_styles = {
                "ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸": {
                    "greeting": "ì•ˆë…•í•˜ì„¸ìš”, ì—¬ëŸ¬ë¶„! ğŸ˜Š",
                    "style": "í•´ë³´ì„¸ìš”"
                },
                "ì •ì¤‘í•˜ê³  ê²©ì‹ìˆëŠ”": {
                    "greeting": "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ.",
                    "style": "í•˜ì‹­ì‹œì˜¤"
                },
                "ìºì£¼ì–¼í•˜ê³  ì¬ë¯¸ìˆëŠ”": {
                    "greeting": "ì•ˆë…•! ğŸ‘‹",
                    "style": "í•´ë´ìš”"
                },
                "ì „ë¬¸ì ì´ê³  ìƒì„¸í•œ": {
                    "greeting": "ì´ ê¸€ì—ì„œëŠ”",
                    "style": "í•©ë‹ˆë‹¤"
                }
            }
            
            style = tone_styles.get(tone, tone_styles["ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸"])
            
            # í…ŒìŠ¤íŠ¸ìš© ì½˜í…ì¸  ìƒì„±
            test_content = f"""{style['greeting']} ì˜¤ëŠ˜ì€ {main_keyword}ì— ëŒ€í•´ ì´ì•¼ê¸°{style['style']}.

## {main_keyword}ë€ ë¬´ì—‡ì¸ê°€ìš”?

{main_keyword}ëŠ” í˜„ì¬ ë§ì€ ê´€ì‹¬ì„ ë°›ê³  ìˆëŠ” ì£¼ì œì…ë‹ˆë‹¤. ìµœê·¼ ë“¤ì–´ ë”ìš± ì¤‘ìš”í•´ì§€ê³  ìˆìœ¼ë©°, ìš°ë¦¬ ì¼ìƒìƒí™œì—ë„ í° ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.

ì‹¤ì œë¡œ ì €ë„ ì²˜ìŒ {main_keyword}ë¥¼ ì ‘í–ˆì„ ë•ŒëŠ” ë§‰ë§‰í–ˆì–´ìš”. í•˜ì§€ë§Œ í•˜ë‚˜ì”© ì•Œì•„ê°€ë‹¤ ë³´ë‹ˆ ì •ë§ í¥ë¯¸ë¡œìš´ ë¶„ì•¼ë”ë¼ê³ ìš”!

## ì™œ {main_keyword}ê°€ ì¤‘ìš”í• ê¹Œìš”?

ì²«ì§¸, {main_keyword}ëŠ” ìš°ë¦¬ì˜ ë¯¸ë˜ë¥¼ ë°”ê¿€ ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ë‘˜ì§¸, ì‹¤ìš©ì ì¸ ì¸¡ë©´ì—ì„œë„ ë§ì€ ë„ì›€ì´ ë©ë‹ˆë‹¤.
ì…‹ì§¸, ê°œì¸ì ì¸ ì„±ì¥ì—ë„ í° ë„ì›€ì´ ë˜ì£ .

ì˜ˆë¥¼ ë“¤ì–´, ì œê°€ ì•„ëŠ” í•œ ë¶„ì€ {main_keyword}ë¥¼ í†µí•´ ì—…ë¬´ íš¨ìœ¨ì„ 30% ì´ìƒ í–¥ìƒì‹œì¼°ë‹¤ê³  í•©ë‹ˆë‹¤. ì •ë§ ë†€ë¼ìš´ ì„±ê³¼ì£ ?

## {main_keyword}ì˜ í•µì‹¬ ìš”ì†Œ

### 1. ê¸°ë³¸ ê°œë… ì´í•´í•˜ê¸°

{main_keyword}ì˜ ê¸°ë³¸ ê°œë…ì€ ìƒê°ë³´ë‹¤ ê°„ë‹¨í•©ë‹ˆë‹¤. í•µì‹¬ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- **ëª…í™•í•œ ëª©í‘œ ì„¤ì •**: ë¬´ì—‡ì„ ë‹¬ì„±í•˜ê³  ì‹¶ì€ì§€ ëª…í™•íˆ {style['style']}
- **ë‹¨ê³„ë³„ ì ‘ê·¼**: í•œ ë²ˆì— ëª¨ë“  ê²ƒì„ í•˜ë ¤ê³  í•˜ì§€ ë§ˆì„¸ìš”
- **ê¾¸ì¤€í•œ ì‹¤ì²œ**: ì‘ì€ ê²ƒë¶€í„° ì‹œì‘{style['style']}

### 2. ì‹¤ì œ ì ìš© ë°©ë²•

ì´ë¡ ì€ ì•Œì•˜ìœ¼ë‹ˆ ì´ì œ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³¼ê¹Œìš”?

**Step 1**: í˜„ì¬ ìƒí™© íŒŒì•…í•˜ê¸°
ë¨¼ì € ìì‹ ì˜ í˜„ì¬ ìƒí™©ì„ ì •í™•íˆ íŒŒì•…{style['style']}. 

**Step 2**: ëª©í‘œ ì„¤ì •í•˜ê¸°
ë‹¬ì„± ê°€ëŠ¥í•œ ì‘ì€ ëª©í‘œë¶€í„° ì‹œì‘{style['style']}.

**Step 3**: ì‹¤í–‰ ê³„íš ìˆ˜ë¦½í•˜ê¸°
êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšì„ ë§Œë“¤ì–´{style['style']}.

## ì‹¤ì „ íŒê³¼ ë…¸í•˜ìš°

ì œê°€ {main_keyword}ë¥¼ í™œìš©í•˜ë©´ì„œ ì–»ì€ ëª‡ ê°€ì§€ íŒì„ ê³µìœ í• ê²Œìš”:

1. **ì‘ê²Œ ì‹œì‘í•˜ê¸°**: ì²˜ìŒë¶€í„° ì™„ë²½í•˜ê²Œ í•˜ë ¤ê³  í•˜ì§€ ë§ˆì„¸ìš”
2. **ê¸°ë¡í•˜ê¸°**: ì§„í–‰ ìƒí™©ì„ ê¸°ë¡í•˜ë©´ ë™ê¸°ë¶€ì—¬ê°€ ë©ë‹ˆë‹¤
3. **ì»¤ë®¤ë‹ˆí‹° í™œìš©**: ê°™ì€ ê´€ì‹¬ì‚¬ë¥¼ ê°€ì§„ ì‚¬ëŒë“¤ê³¼ êµë¥˜{style['style']}
4. **ì‹¤íŒ¨ë¥¼ ë‘ë ¤ì›Œí•˜ì§€ ì•Šê¸°**: ì‹¤íŒ¨ë„ ë°°ì›€ì˜ ê³¼ì •ì…ë‹ˆë‹¤

## ì£¼ì˜í•  ì 

ë¬¼ë¡  {main_keyword}ë¥¼ í™œìš©í•  ë•Œ ì£¼ì˜í•´ì•¼ í•  ì ë„ ìˆìŠµë‹ˆë‹¤:

- ë„ˆë¬´ ê¸‰í•˜ê²Œ ì§„í–‰í•˜ì§€ ë§ˆì„¸ìš”
- ê¸°ë³¸ê¸°ë¥¼ íƒ„íƒ„íˆ ë‹¤ì§€ì„¸ìš”
- ì§€ì† ê°€ëŠ¥í•œ ë°©ë²•ì„ ì„ íƒ{style['style']}

## ë” ë‚˜ì•„ê°€ê¸°

ì´ì œ ê¸°ë³¸ì ì¸ ë‚´ìš©ì€ ë‹¤ ì•Œì•„ë´¤ìœ¼ë‹ˆ, ë” ê¹Šì´ ìˆê²Œ ê³µë¶€í•˜ê³  ì‹¶ë‹¤ë©´ ë‹¤ìŒì„ ì¶”ì²œí•©ë‹ˆë‹¤:

- ê´€ë ¨ ì„œì  ì½ê¸°
- ì˜¨ë¼ì¸ ê°•ì˜ ìˆ˜ê°•
- ì‹¤ìŠµ í”„ë¡œì íŠ¸ ì§„í–‰
- ì „ë¬¸ê°€ ë©˜í† ë§

ì—¬ëŸ¬ë¶„ë„ {main_keyword}ë¥¼ í†µí•´ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ë°œê²¬í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤! ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ì–¸ì œë“  ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”. 

ë‹¤ìŒì—ëŠ” ë” ì‹¬í™”ëœ ë‚´ìš©ìœ¼ë¡œ ì°¾ì•„ëµ™ê² ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ë„ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ™"""
            
            claude_content = {
                "title": f"{main_keyword}ì˜ ëª¨ë“  ê²ƒ: ì´ˆë³´ìë¥¼ ìœ„í•œ ì™„ë²½ ê°€ì´ë“œ",
                "meta_description": f"{main_keyword}ì— ëŒ€í•œ ê¸°ì´ˆë¶€í„° ì‹¤ì „ê¹Œì§€, ì‰½ê³  ì¬ë¯¸ìˆê²Œ ì•Œì•„ë³´ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.",
                "content": test_content,
                "word_count": len(test_content)
            }
            
            logger.info("í…ŒìŠ¤íŠ¸ìš© ëŒ€ì²´ ì½˜í…ì¸  ìƒì„± ì™„ë£Œ")
            
        
        # ì‹¤ì œ Unsplash APIë¡œ ì´ë¯¸ì§€ ìƒì„±
        from app.services.unsplash_service import get_unsplash_service
        
        try:
            unsplash_service = get_unsplash_service()
            
            # ëŒ€í‘œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            featured_image = await unsplash_service.get_featured_image(keywords)
            if not featured_image:
                # ëŒ€ì²´ ì´ë¯¸ì§€
                featured_image = {
                    "id": f"fallback_{random.randint(1000, 9999)}",
                    "url": f"https://images.unsplash.com/photo-1516321318423-f06f85e504b3?auto=format&fit=crop&w=1200&q=80",
                    "thumb_url": f"https://images.unsplash.com/photo-1516321318423-f06f85e504b3?auto=format&fit=crop&w=400&q=80",
                    "alt_text": f"{keywords[0]}ì— ê´€ë ¨ëœ ì´ë¯¸ì§€",
                    "attribution": {
                        "photographer": "Unsplash",
                        "source": "Unsplash"
                    },
                    "width": 1200,
                    "height": 800
                }
            
            # ì½˜í…ì¸ ìš© ì¶”ê°€ ì´ë¯¸ì§€ë“¤
            content_images = await unsplash_service.get_content_images(keywords, claude_content['title'])
            
            logger.info(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼", 
                       title_based_count=len(content_images['title_based']),
                       keyword_based_count=len(content_images['keyword_based']))
            
            # ë³¸ë¬¸ì— ì´ë¯¸ì§€ ì²¨ë¶€í•˜ê¸°
            content_with_images = claude_content['content']
            
            # ë³¸ë¬¸ ì¤‘ê°„ì— ì´ë¯¸ì§€ ì‚½ì…
            content_lines = content_with_images.split('\n')
            total_lines = len(content_lines)
            insert_pos = 0  # ì´ˆê¸°ê°’ ì„¤ì •
            images_inserted = 0
            
            # 500ìë§ˆë‹¤ ì´ë¯¸ì§€ 1ê°œì”© ì‚½ì…
            content_length = len(content_with_images)
            image_count = max(1, content_length // 500)  # 500ìë§ˆë‹¤ 1ê°œ
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ëª¨ìŒ
            available_images = []
            if content_images['title_based']:
                available_images.extend(content_images['title_based'])
            if content_images['keyword_based']:
                available_images.extend(content_images['keyword_based'])
            
            # ì´ë¯¸ì§€ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ë°˜ë³µ ì‚¬ìš©
            if available_images:
                while len(available_images) < image_count:
                    available_images.extend(available_images[:min(len(available_images), image_count - len(available_images))])
            
            # ë¬¸ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ì§€ ì‚½ì…
            if available_images:
                # í˜„ì¬ê¹Œì§€ì˜ ë¬¸ì ìˆ˜ ê³„ì‚°
                char_count = 0
                inserted_images = 0
                new_lines = []
                
                for line in content_lines:
                    new_lines.append(line)
                    char_count += len(line)
                    
                    # 500ìë§ˆë‹¤ ì´ë¯¸ì§€ ì‚½ì… (ë‹¨ë½ ê²½ê³„ í™•ì¸)
                    if char_count >= (inserted_images + 1) * 500 and inserted_images < min(image_count, len(available_images)):
                        # í˜„ì¬ ì¤„ì´ ë¹ˆ ì¤„ì´ë©´ ë°”ë¡œ ì‚½ì…
                        if line.strip() == '':
                            img = available_images[inserted_images]
                            image_markdown = f"\n![{img['alt_text']}]({img['url']})\n*ì‚¬ì§„: {img['attribution']['photographer']} (Unsplash)*\n"
                            new_lines.append(image_markdown)
                            inserted_images += 1
                            images_inserted += 1
                            logger.info(f"{inserted_images}ë²ˆì§¸ ì´ë¯¸ì§€ ì‚½ì… (500ì ê°„ê²©)", chars=char_count, url=img['url'])
                
                content_lines = new_lines
            
            # ì´ë¯¸ì§€ê°€ ì²¨ë¶€ëœ ìµœì¢… ë³¸ë¬¸
            content_with_images = '\n'.join(content_lines)
            claude_content['content'] = content_with_images
            
            logger.info(f"ì´ë¯¸ì§€ ì²¨ë¶€ ì™„ë£Œ", total_inserted=images_inserted)
            
            suggested_images = content_images
            
        except Exception as img_error:
            logger.error(f"Unsplash ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {img_error}")
            # ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
            main_keyword = keywords[0]
            featured_image = {
                "id": f"fallback_{random.randint(1000, 9999)}",
                "url": f"https://images.unsplash.com/photo-1516321318423-f06f85e504b3?auto=format&fit=crop&w=1200&q=80",
                "thumb_url": f"https://images.unsplash.com/photo-1516321318423-f06f85e504b3?auto=format&fit=crop&w=400&q=80",
                "alt_text": f"{main_keyword}ì— ê´€ë ¨ëœ ì´ë¯¸ì§€",
                "attribution": {
                    "photographer": "Unsplash",
                    "source": "Unsplash"
                },
                "width": 1200,
                "height": 800
            }
            
            # ì´ë¯¸ì§€ API ì˜¤ë¥˜ ì‹œ ì´ë¯¸ì§€ ì—†ì´ ì§„í–‰
            suggested_images = {
                "title_based": [],
                "keyword_based": []
            }
        
        # Supabase blog_posts í…Œì´ë¸”ì— ì½˜í…ì¸  ì €ì¥
        try:
            # blog_platform ì •ë³´ì—ì„œ í”Œë«í¼ ID ì°¾ê¸°
            platform_name = request.get('blog_platform', {}).get('name')
            platform_type = request.get('blog_platform', {}).get('platform_type')
            platform_url = request.get('blog_platform', {}).get('url')
            
            # í”Œë«í¼ ID ì¡°íšŒ
            platform_result = supabase_client.table('blog_platforms').select("id").eq('name', platform_name).execute()
            
            platform_id = None
            if platform_result.data:
                platform_id = platform_result.data[0]['id']
            else:
                # í”Œë«í¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì²« ë²ˆì§¸ í”Œë«í¼ ì‚¬ìš©
                first_platform = supabase_client.table('blog_platforms').select("id").limit(1).execute()
                if first_platform.data:
                    platform_id = first_platform.data[0]['id']
            
            if platform_id:
                post_data = {
                    "platform_id": platform_id,
                    "title": claude_content["title"],
                    "content": claude_content["content"],
                    "meta_description": claude_content["meta_description"],
                    "featured_image_url": featured_image.get("url") if featured_image else None,
                    "status": "draft",  # ì´ˆê¸° ìƒíƒœëŠ” draftë¡œ ì„¤ì •
                    "views": 0,  # ì‹¤ì œ ê°’ìœ¼ë¡œ ì‹œì‘
                    "likes": 0,  # ì‹¤ì œ ê°’ìœ¼ë¡œ ì‹œì‘
                    "comments": 0,  # ì‹¤ì œ ê°’ìœ¼ë¡œ ì‹œì‘
                    "tags": keywords,  # í‚¤ì›Œë“œë¥¼ íƒœê·¸ë¡œ ì €ì¥
                    "published_url": None,  # ì•„ì§ ë°œí–‰ ì•ˆë¨
                    "published_at": None,  # ì•„ì§ ë°œí–‰ ì•ˆë¨
                    "created_at": datetime.now().isoformat()
                }
                
                # blog_posts í…Œì´ë¸”ì— ì €ì¥
                insert_result = supabase_client.table('blog_posts').insert(post_data).execute()
                
                if insert_result.data:
                    saved_post = insert_result.data[0]
                    logger.info(f"í¬ìŠ¤íŠ¸ê°€ Supabaseì— ì €ì¥ë¨", post_id=saved_post.get('id'))
                else:
                    logger.warning("í¬ìŠ¤íŠ¸ ì €ì¥ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
            else:
                logger.error("í”Œë«í¼ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
        except Exception as save_error:
            logger.error(f"í¬ìŠ¤íŠ¸ Supabase ì €ì¥ ì‹¤íŒ¨: {save_error}")
            # ì €ì¥ ì‹¤íŒ¨í•´ë„ ìƒì„±ëœ ì½˜í…ì¸ ëŠ” ë°˜í™˜
        
        # ì‘ë‹µ ë°ì´í„°
        content_response = {
            "title": claude_content["title"],
            "content": claude_content["content"],
            "meta_description": claude_content["meta_description"],
            "word_count": claude_content["word_count"],
            "ai_model_used": settings.claude_model,
            "featured_image": featured_image,
            "suggested_images": suggested_images
        }
        
        return {
            "success": True,
            "message": "ì½˜í…ì¸ ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ê³  ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
            "content": content_response,
            "generation_info": {
                "keywords_used": keywords,
                "content_type": content_type,
                "target_length": target_length,
                "actual_length": claude_content["word_count"],
                "tone": tone,
                "generated_at": datetime.now().isoformat(),
                "ai_model": settings.claude_model
            }
        }
        
    except Exception as e:
        logger.error(f"Content generation error: {e}")
        return {
            "success": False,
            "message": f"ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }